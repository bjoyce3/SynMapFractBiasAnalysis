{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For importing data and parsing data\n",
    "from operator import itemgetter\n",
    "import pprint\n",
    "\n",
    "\n",
    "#Converting parsed data into raw parsed data output to csv\n",
    "import csv\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "#For analyzing raw parsed data\n",
    "import collections, re\n",
    "from collections import OrderedDict\n",
    "\n",
    "    #had to uninstall python-dateutil and use old version dateutil 2.2 to avoid error\n",
    "    #sudo pip uninstall python-dateutil\n",
    "    #sudo pip install python-dateutil==2.2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "#had to install this using pip on local computer\n",
    "from natsort import natsorted, natsort_key\n",
    "\n",
    "#Library to pull query genome chromosome information from CoGe API\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "translate() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0b0911b43598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mgenus_species\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mspecies_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenus_species\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mspecies_name_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecies_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(){}[]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: translate() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "#For importing data and parsing. SynMap_import used to build main d{} data structure. GFF_target_\n",
    "synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/Sorghum-maize-synmap.txt'\n",
    "gff_target_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/Sorghum_bicolor_sorghum_annos1-cds1-id_typename-nu1-upa1-add_chr0.gid28853.gff'\n",
    "\n",
    "#gff_query_import_file = ('')\n",
    "\n",
    "d = {}  # initialize dictionary to contain the array of syntenic genome1_chrs, genome1_genes, genome2_chrs, and genome2_genes\n",
    "\n",
    "\n",
    "#Determines the Genus species of target chromosome\n",
    "genus_species = ''\n",
    "with open(gff_target_import_file) as gff_file:\n",
    "    for line in gff_file:\n",
    "        if line[0:15] == '##Organism name':\n",
    "            genus_species = line[17:-1]\n",
    "            species_name = genus_species.replace(' ','_')\n",
    "            species_name_filter = species_name.translate(None, '(){}[]')\n",
    "\n",
    "\n",
    "#Parsed data and raw output to csv\n",
    "gff_genes_target = {}  # initializes dictionary for organization of genes on chromosomes within target genome according to start bp\n",
    "\n",
    "#Output\n",
    "gff_sort_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/\"+str(species_name_filter)+ \".txt\")\n",
    "synmap_dictionary_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/\" +str(species_name_filter)+ \".txt\")\n",
    "fract_bias_raw_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/\" +str(species_name_filter)+ \"output.csv\")\n",
    "retention_calc_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/\"+str(species_name_filter+\".csv\"))\n",
    "\n",
    "#Analysis of parsed data\n",
    "\n",
    "target_lst = []\n",
    "query_lst = []\n",
    "\n",
    "##METHODS\n",
    "\n",
    "#Identify each chromosome present in genomes from dictionaries made previously\n",
    "def chr_id(input_dict):\n",
    "    for item in input_dict:\n",
    "        if not item in target_lst:\n",
    "            target_lst.append(item)\n",
    "        for gene in input_dict[item]:\n",
    "            for chr in input_dict[item][gene]:\n",
    "                if not chr in query_lst:\n",
    "                    query_lst.append(chr)\n",
    "\n",
    "                \n",
    "                    \n",
    "#http://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator-in-python\n",
    "def window(seq, n):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pina & Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Pina-Rice/pina_gdcoords_overlap40.txt'\n",
    "#gff_target_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Pina-Rice/Ananas_comosus_pineapple_v6.gff'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorghum & Maize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/SorghumMaize_gcoords_merge60_syntenicdepth40.txt'\n",
    "#gff_target_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/Sorghum_bicolor_6807_prodrun.gff'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brassicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##A. thaliana - Brassica rapa (1:3)\n",
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/Athaliana_Brapa_gcoords_1-3.txt'\n",
    "#gff_target_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/Arabidopsis_thaliana.gid25869.gff'\n",
    "\n",
    "##A. thaliana - Brassica napus (1:6)\n",
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/Athaliana_Bnapus_1-6.txt'\n",
    "#gff_target_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/Arabidopsis_thaliana.gid25869.gff'\n",
    "\n",
    "##Brassica napus - Brassica rapa (2:1)\n",
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/Bnapus_Brapa_gcoords_2-1.txt'\n",
    "#gff_target_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/Brassica_rapa.gid24668.gff'\n",
    "\n",
    "\n",
    "##OUTPUT\n",
    "#gff_sort_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/brassica/ALL_GFF_sorted_\"+str(species_name_filter)+ \".txt\")\n",
    "#synmap_dictionary_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/brassica/ALL_dictionary_syntenic genes_\" +str(species_name_filter)+ \".txt\")\n",
    "#fract_bias_raw_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/brassica/ALL_fractbias_\" +str(species_name_filter)+ \"output.csv\")\n",
    "#retention_calc_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/brassica/Window_output_\"+str(species_name_filter+\".csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gar-trout\n",
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/fish/gar-trout_syndepth40_maxks1-47.txt'\n",
    "#gff_target_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/fish/.gff'\n",
    "\n",
    "#pike-trout\n",
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/fish/pike-trout_syndepth40_ksmax1-1.txt'\n",
    "#gff_target_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/fish/Esox_lucius_pike_25161.gff'\n",
    "\n",
    "#Output\n",
    "#gff_sort_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/fish/ALL_GFF_sorted_\"+str(species_name_filter)+ \".txt\")\n",
    "#synmap_dictionary_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/fish/ALL_dictionary_syntenic genes_\" +str(species_name_filter)+ \".txt\")\n",
    "#gff_genes_target = {}  # initializes dictionary for organization of genes on chromosomes within genome1 according to start bp\n",
    "#fract_bias_raw_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/fish/ALL_fractbias_\" +str(species_name_filter)+ \"output.csv\")\n",
    "\n",
    "#Analysis of parsed data\n",
    "#retention_calc_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/fish/Window_output_\"+str(species_name_filter+\".csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Poplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Theobroma-poplar (1:2)\n",
    "#synmap_import_file = ('/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Vitis-poplar/Theobroma-poplar_1-2_gcoords.txt')\n",
    "#gff_target_import_file = ('/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Vitis-poplar/Theobroma_cacao_gid10997.gff')\n",
    "#OUTPUT\n",
    "#\n",
    "#\n",
    "\n",
    "#Vitis-poplar  (1:2)\n",
    "#synmap_import_file = ('/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Vitis-poplar/Vitis_poplar_1-2_gcoords.txt')\n",
    "#gff_target_import_file = ('/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Vitis-poplar/Vitis_vinifera_grape_gid19990.gff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#User Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set target genome and query genome\n",
    "\n",
    "args_target = \"16888\" #Oryza\n",
    "#\"25869\" #arabidopsis\n",
    "#'6807' #sorghum \n",
    "#'25734'  #pina\n",
    "#'25161'  #pike\n",
    "#'25003'  #gar\n",
    "#'19990' #vitis vinifera\n",
    "#'10997' #theobroma\n",
    "#'24668'  #Brassica rapa\n",
    "#\"16888\" #Oryza\n",
    "\n",
    "#Set whether to use all genes or \n",
    "args_all_genes = True  #True == use all genes in target genome; False == use only genes with at least one syntenic pair\n",
    "\n",
    "window_size = 100\n",
    "\n",
    "\n",
    "#NEW ARGS TO ADD TO GECO\n",
    "args_query = '8082'  #Zea mays\n",
    "#'24668'  #Brassica rapa\n",
    "#'8082'  #Zea mays\n",
    "#'20192'  #Brassica napus\n",
    "\n",
    "args_numtargetchr = int(12)\n",
    "args_numquerychr = int(10)\n",
    "args_remove_random_unknown = True #True == removes random and unknown chromosome names, False == removes nothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and Making Data Structures\n",
    "\n",
    "Reads SynMap and GFF files and parse data into data arrays. \n",
    "\n",
    "SynMap data is put into nested dictionary called 'd':\n",
    "d{target_chr\n",
    "    {target_gene\n",
    "        {query_chr\n",
    "            {query gene}\n",
    "  }}}\n",
    "\n",
    "GFF data from the target genome is put into a nested dictionary call 'gff_genes_target':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Calls Genome Fetch CoGE API to get query genome and target chromosomes and orders them\"\"\"\n",
    "\n",
    "#retrieves api chromsome lists and length and moves json() object into Python dictionary\n",
    "query_api = requests.get(\"https://genomevolution.org/coge/api/v1/genomes/\" + str(args_query))\n",
    "target_api = requests.get(\"https://genomevolution.org/coge/api/v1/genomes/\" + str(args_target))\n",
    "query_api = query_api.json()\n",
    "target_api = target_api.json()\n",
    "\n",
    "\n",
    "#initializes dictionaries to drop api data into\n",
    "target_api_chrs = []\n",
    "target_api_chrs_sorted = []\n",
    "target_api_chrs_sorted_filtered = []\n",
    "target_api_chrs_sorted_name = []\n",
    "target_api_chrs_final = []\n",
    "query_api_chrs = []\n",
    "query_api_chrs_sorted = []\n",
    "query_api_chrs_sorted_filtered = []\n",
    "query_api_chrs_sorted_name = []\n",
    "query_api_chrs_final = []\n",
    "\n",
    "#query genome chromosomes parsed, restricted by length largest -> smallest, and sorted according to name\n",
    "for chr in query_api['chromosomes']:\n",
    "    if args_remove_random_unknown == True:\n",
    "        if \"Random\" in chr['name'] or \"random\" in chr['name'] or \"Unknown\" in chr['name'] or \"unknown\" in chr['name']:\n",
    "            continue\n",
    "        else:\n",
    "            query_api_chrs.append((chr['name'], chr['length']))\n",
    "    if args_remove_random_unknown == False:\n",
    "        query_api_chrs.append((chr['name'], chr['length']))\n",
    "query_api_chrs_sorted = natsorted(query_api_chrs, key=lambda chr: chr[1], reverse=True)\n",
    "query_api_chrs_sorted_filtered = query_api_chrs_sorted[0:args_numquerychr]\n",
    "query_api_chrs_sorted_name = natsorted(query_api_chrs_sorted_filtered, key=lambda chr: chr[0])\n",
    "for chr in query_api_chrs_sorted_name:\n",
    "    query_api_chrs_final.append(chr[0])\n",
    "\n",
    "#target genome chromosomes parsed, restricted by length largest ->smallest, and sorted according to name\n",
    "for chr in target_api['chromosomes']:\n",
    "    if args_remove_random_unknown == True:\n",
    "        if \"Random\" in chr['name'] or \"random\" in chr['name'] or \"Unknown\" in chr['name'] or \"unknown\" in chr['name']:\n",
    "            continue\n",
    "        else:\n",
    "            target_api_chrs.append((chr['name'], chr['length']))\n",
    "    if args_remove_random_unknown == False:\n",
    "        target_api_chrs.append((chr['name'], chr['length']))\n",
    "target_api_chrs_sorted = natsorted(target_api_chrs, key=lambda chr: chr[1], reverse=True)\n",
    "target_api_chrs_sorted_filtered = target_api_chrs_sorted[0:args_numtargetchr]\n",
    "target_api_chrs_sorted_name = natsorted(target_api_chrs_sorted_filtered, key=lambda chr: chr[0])\n",
    "for chr in target_api_chrs_sorted_name:\n",
    "    target_api_chrs_final.append(chr[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads SynMap files and parses data into columns in array\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "d = {}\n",
    "\n",
    "with open(synmap_import_file, 'r') as f:  # open SynMap file containing syntenic genes\n",
    "    synmap_rowcount = 0\n",
    "    cols = []  # list for parsing columns from SynMap data\n",
    "    decimal_strip_check_target_gene = 0\n",
    "    for line in f:  # for loop to parse columns\n",
    "        new_line = line.replace('||', '\\t')  #converts || into tabs for universal delimination\n",
    "        if line[0] != '#' and line[0] != '\\n':  #sorts out columns containing syntenic block information/headings\n",
    "            cols = new_line.split('\\t', )  #splits all syntenic gene pair lines into parsed columns in a list\n",
    "            synmap_rowcount += 1\n",
    "            global target_chr\n",
    "            global target_gene\n",
    "            global query_chr\n",
    "            global query_gene\n",
    "            if synmap_rowcount == 1:            \n",
    "                #clean ID subgenome A from the column on left of data\n",
    "                ida = cols[0]\n",
    "                ida = ida[1:cols[0].index('_')]\n",
    "#Determines which are target and query genes                \n",
    "            if args_target == ida:\n",
    "                target_chr = cols[1]\n",
    "                if any(target_chr in s for s in target_api_chrs_final):\n",
    "                    target_gene = str(cols[7]) #.rsplit(\".\", 1)[0]  #puts all genome1_genes with synteny into a list\n",
    "                    #decimal_strip_check_target_gene = target_gene.find('.')\n",
    "                    #if not decimal_strip_check_target_gene == (-1):\n",
    "                        #target_gene = target_gene[:(decimal_strip_check_target_gene)]\n",
    "                else:\n",
    "                    continue\n",
    "                query_chr = str(cols[13])  #puts all genome2_chrs with synteny to genes in genome1 into a list\n",
    "                if any(query_chr in s for s in query_api_chrs_final):\n",
    "                    query_gene = str(cols[19])  #.rsplit(\".\", 1)[0]  #puts all genome2_genes with synteny to genes in a genome1 into a list\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                target_chr = cols[13]\n",
    "                if any(target_chr in s for s in target_api_chrs_final):\n",
    "                    target_gene = str(cols[19])\n",
    "                    #decimal_strip_check_target_gene = target_gene.find('.')\n",
    "                    #if not decimal_strip_check_target_gene == (-1):\n",
    "                    #    target_gene = target_gene[:(decimal_strip_check_target_gene)]\n",
    "                    #puts all genome1_genes with synteny into a list\n",
    "                else:\n",
    "                    continue\n",
    "                query_chr = str(cols[1])  #puts all genome2_chrs with synteny to genes in genome1 into a list\n",
    "                if any(query_chr in s for s in query_api_chrs_final):\n",
    "                    query_gene = cols[7]  #.rsplit(\".\", 1)[0]  #puts all genome2_genes with synteny to genes in a genome1 into a list\n",
    "                else:\n",
    "                    continue\n",
    "            if not target_chr in d:\n",
    "                d[target_chr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "            if not target_gene in d[target_chr]:\n",
    "                d[target_chr][target_gene] = {}  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "            if not query_chr in d[target_chr][target_gene]:\n",
    "                d[target_chr][target_gene][query_chr] = query_gene  #initializes nested dictionary-third level at genome2_chr\n",
    "\n",
    "\n",
    "#check lengths of synmap data structure\n",
    "\"\"\"for tchr in d:\n",
    "    #print \"Target Chromosome\"\n",
    "    print tchr\n",
    "    #print len(d[tchr])\n",
    "    for tgene in d[tchr]:\n",
    "        #print \"length of target gene\"\n",
    "        #print len(d[tchr][tgene])\n",
    "        for qchr in d[tchr][tgene]:\n",
    "            #print \"length of qchr\"\n",
    "            #print len(d[tchr][tgene][qchr])\n",
    "            print \"     \" + str(qchr)\n",
    "            #print d[tchr][tgene][qchr]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"Create hashable data structure to look up gene/CDS name. CDS_name_dict: CDS_key_name: 1 if TRUE\"\n",
    "CDS_name_dict = {}  #initializes the CDS name dictionary for looking up if CDS already have been identified\n",
    "gff_genes_target = {}\n",
    "\n",
    "'''Reads GFF from target genome and puts into data strcuture gff_genes'''\n",
    "with open(gff_target_import_file, 'r') as g:  # opens gff file\n",
    "    gffcols = []  #list of parsed gff columns\n",
    "    chr = []  #initialize list of chromosomes present in genome1 gff file\n",
    "    for line in g:\n",
    "        new_line = line.replace(';', '\\t')  #makes subdelims universal in gff file from CoGe\n",
    "        new_line = new_line.replace('Name=', '')  #strips Name= off gene_name in gff file from CoGe\n",
    "        if new_line[0] != '#' and new_line[0] != '\\n':  #selects only lines with CDS information\n",
    "            gffcols = new_line.split('\\t', )  #parses all column\n",
    "            if (any(gffcols[0] in s for s in target_api_chrs_final) and (gffcols[2] == 'CDS')):  #selects only 'CDS' lines for consideration\n",
    "                chr = gffcols[0]  #adds genome1_chrs to list\n",
    "                if not chr in gff_genes_target:\n",
    "                    gff_genes_target[chr] = []  #initializes chr list in dictionary if chr does not exist yet\n",
    "                gene_name = str(gffcols[-1])   #[9]).rsplit(\".\", 1)[0]\n",
    "                #gene_name = gene_name.rsplit(\".\", 1)[0]\n",
    "                gene_name = gene_name.rstrip(\"\\n\")\n",
    "                gene_name1 = gene_name[9:] #adds targetgenome_genes to list and removes the \"ID=\" added by CoGe\n",
    "                start = int(gffcols[3])  #adds targetgenome_gene start bp to list for ordering as integer\n",
    "                stop = int(gffcols[4])  #adds targetgenome_gene stop bp to list ?for ordering? as integer\n",
    "                try:\n",
    "                    CDS_name_dict[str(gene_name1)] == 1\n",
    "                    continue\n",
    "                except KeyError:\n",
    "                    gff_genes_target[chr].append(dict(gene_name=gene_name1, start=start, stop=stop))\n",
    "                    CDS_name_dict[str(gene_name1)] = 1\n",
    "\n",
    "\n",
    "#Checking GFF and ordered chromosome data structures\n",
    "\"\"\"print \"Length of CDS_NAME_DICT:\"\n",
    "print len(CDS_name_dict)                \n",
    "\n",
    "sm = 0\n",
    "for tchr in gff_genes_target:\n",
    "    #if tchr == \"A01\":\n",
    "    #    print gff_genes_target[tchr]\n",
    "    print \"Length of gff_genes_target_tchr\" + str(tchr)\n",
    "    print len(gff_genes_target[tchr])\n",
    "    sm = sm + len(gff_genes_target[tchr])\n",
    "print sm\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Sorts GFF genes within target chromosomes by start position'''\n",
    "gff_sort_all = {}\n",
    "gff_sort_all = natsorted(gff_genes_target)\n",
    "\n",
    "\n",
    "for chr in gff_genes_target:\n",
    "    gff_genes_sorted = sorted(gff_genes_target[chr], key=itemgetter('start'))  #Creates dictionary for searching genes against::CONSIDER sorting on midpoint of genes rather than\n",
    "    gff_genes_target[chr] = gff_genes_sorted        \n",
    "    \n",
    "#CONSIDER WRITING A CHECK PROGRAM TO RETURN TRUE IF ALL VALUES ARE SORTED OR FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Writes out SynMap dictionary and sorted GFF gene list to document for parsed output'''\n",
    "\n",
    "with open(str(gff_sort_output_file), 'w') as h:\n",
    "\th.write(str(gff_genes_target))\n",
    "with open(synmap_dictionary_output_file, 'w+') as i:\n",
    "    i.write(str(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Determine Gene Sorting Preference: all genes or at least one syntenic gene\n",
    "If args_all_genes == True\n",
    "If args_all_genes == False: SynMap data is filtered to remove any target genome genes that do not match to any genes present on the query genome chromosomes. Specifically: any {target_chr: target_gene:} that is 'False' for all query chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Determine syntenic gene pairs present and output Raw Data CSV file from parsed data'''\n",
    "\n",
    "#Deprecated method call to determine genome chrs\n",
    "chr_id(d)\n",
    "target_lst = natsorted(target_lst)\n",
    "query_lst = natsorted(query_lst)\n",
    "\n",
    "print query_api_chrs_final\n",
    "\n",
    "windanalysis_input_dict = {}\n",
    "\n",
    "\n",
    "with open(str(fract_bias_raw_output_file), 'w') as csvfile:\n",
    "    headers = ['Target Chromosome', 'Target Gene Name', 'Gene Order on Target Chromosome']\n",
    "    headers.extend(query_api_chrs_final)\n",
    "    headers.extend(query_api_chrs_final)\n",
    "    writer = csv.writer(csvfile, dialect='excel', delimiter=',', lineterminator='\\n')\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    if args_all_genes == True:\n",
    "        for tchr in gff_genes_target:\n",
    "            col0 = chr #writes Pineapple chr number\n",
    "            count = 0\n",
    "            for diction in gff_genes_target[tchr]:\n",
    "                gene = diction['gene_name']\n",
    "                col1 = gene #writes gene name\n",
    "                count += 1\n",
    "                col2 = count #writes pineapple gene number on pineapple chr\n",
    "                #Find the query chr genes and output to columns: first gff info (col0-3), query chr (col 4-n), query chr-gene (col n+1-m)\n",
    "                syntenic_query_gene_presence_data = []\n",
    "                syntenic_query_gene_name = []\n",
    "                for qchr in query_api_chrs_final:\n",
    "                    if not tchr in windanalysis_input_dict:\n",
    "                        windanalysis_input_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "                    if not qchr in windanalysis_input_dict[tchr]:\n",
    "                        windanalysis_input_dict[tchr][qchr] = []  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "\n",
    "                    try:\n",
    "                        syn_gene = d[tchr][gene][qchr]\n",
    "                        syntenic_query_gene_presence_data.append(True)\n",
    "                        syntenic_query_gene_name.append(syn_gene)\n",
    "                        windanalysis_input_dict[tchr][qchr].append(True)\n",
    "                    except KeyError:\n",
    "                        syntenic_query_gene_presence_data.append(False)\n",
    "                        syntenic_query_gene_name.append(\"\")\n",
    "                        windanalysis_input_dict[tchr][qchr].append(False)\n",
    "                rows = [tchr, col1, col2]\n",
    "                rows.extend(syntenic_query_gene_presence_data)\n",
    "                rows.extend(syntenic_query_gene_name)\n",
    "                writer.writerow(rows)                                           \n",
    "                    \n",
    "    elif args_all_genes == False:\n",
    "        for tchr in gff_genes_target:\n",
    "            col0 = chr #writes target chr number\n",
    "            count = 0\n",
    "            for diction in gff_genes_target[tchr]:\n",
    "                gene = diction['gene_name']\n",
    "                col1 = gene #writes target gene name\n",
    "                count += 1\n",
    "                col2 = count #writes target gene number on target chr\n",
    "                #Find the query chr genes and output to columns: first gff info (col0-3), query chr (col 4-n), query chr-gene (col n+1-m)\n",
    "                syntenic_query_gene_presence_data = []\n",
    "                syntenic_query_gene_name = []\n",
    "                for qchr in query_api_chrs_final:\n",
    "                    if not tchr in windanalysis_input_dict:\n",
    "                        windanalysis_input_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "                    if not qchr in windanalysis_input_dict[tchr]:\n",
    "                        windanalysis_input_dict[tchr][qchr] = []  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "\n",
    "                    try:\n",
    "                        syn_gene = d[tchr][gene][qchr]\n",
    "                        syntenic_query_gene_presence_data.append(True)\n",
    "                    except KeyError:\n",
    "                        syntenic_query_gene_presence_data.append(False)\n",
    "                                \n",
    "                if sum(syntenic_query_gene_presence_data) >= 1:\n",
    "                    for qchr in query_api_chrs_final:\n",
    "                        try:\n",
    "                            syn_gene = d[tchr][gene][qchr]\n",
    "                            syntenic_query_gene_name.append(syn_gene)\n",
    "                            windanalysis_input_dict[tchr][qchr].append(True)\n",
    "                        except KeyError:\n",
    "                            syntenic_query_gene_name.append(\"\")\n",
    "                            windanalysis_input_dict[tchr][qchr].append(False)                    \n",
    "                    rows = [tchr, col1, col2]\n",
    "                    rows.extend(syntenic_query_gene_presence_data)\n",
    "                    rows.extend(syntenic_query_gene_name)\n",
    "                    writer.writerow(rows) \n",
    "\n",
    "                elif sum(syntenic_query_gene_presence_data) < 1:               \n",
    "                    continue\n",
    "                else:\n",
    "                    print 'Target gene not classified'\n",
    "                    continue\n",
    "\n",
    "    else:\n",
    "        print \"Genes to be used (all genes or at least one syntenic gene) are not defined\"\n",
    "\n",
    "        \n",
    "##FOR INVESTIGATING COMPARISON DATA STRUCTURE\n",
    "  \n",
    "\"\"\"print windanalysis_input_dict\n",
    "\n",
    "print \"Number of windanalysis_input chromosomes = \"+str(len(windanalysis_input_dict))        \n",
    "\n",
    "for tchr in windanalysis_input_dict:\n",
    "    print \"Name of windanalysis_input target chromosome = \" + str(tchr)\n",
    "    print len(windanalysis_input_dict[tchr])\n",
    "    for qchr in windanalysis_input_dict[tchr]:\n",
    "        print qchr\n",
    "        print len(windanalysis_input_dict[tchr][qchr])\"\"\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Data Structures\n",
    "\n",
    "Looks through each chromosome in target genome (tchr), and goes through each gene gene on that target chromosome (determined by the GFF uploaded above according to bp position on that target chromosome) to compare to the query genome (query chromsomes). If a target gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# '''Analysis: for each chromosome in genome1 read the genes on a chromosome and compare to subgenome array of syntenic genes'''\n",
    "\n",
    "data_output0 = []\n",
    "data_output1 = []\n",
    "data_output2 = []\n",
    "data_output3 = []\n",
    "output_dict = {}\n",
    "alphanum_output_dict = {}\n",
    "numsorted_output_dict = {}\n",
    "\n",
    "#Process windows 100genes/sliding window and \n",
    "#output to nested dictionary data structure output_dict{target chr:}{query chr}{window count:retention%}\n",
    "for tchr in windanalysis_input_dict:\n",
    "    tchr_counter = tchr\n",
    "    for qchr in windanalysis_input_dict[tchr]:\n",
    "        counter = 0\n",
    "        qchr_counter = qchr\n",
    "        if not tchr in output_dict:\n",
    "            output_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "        if not qchr in output_dict[tchr]:\n",
    "            output_dict[tchr][qchr] = {}  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "        try:\n",
    "            if (int(len(windanalysis_input_dict[tchr][qchr]))) >= window_size:\n",
    "                for each in window(windanalysis_input_dict[tchr][qchr], window_size):\n",
    "                    counter += 1\n",
    "                    data_output2 = float(sum(each)) / float(window_size)\n",
    "                    output_dict[tchr][qchr][counter] = round(data_output2*100.) \n",
    "                    \n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "\n",
    "#Sort output_dict for tchr alphanumberic at top level\n",
    "#if tchr are only integers (not alpha&numeric) the except statement will sort just integers\n",
    "\n",
    "'''try:   \n",
    "    alphanumbsort = lambda k,v: [k, int(v)]\n",
    "    output_dict = collections.OrderedDict(sorted(output_dict.items(), key=lambda t: alphanumbsort(*re.match(r'([a-zA-Z]+)(\\d+)',t[0]).groups())))\n",
    "    print \"alphanum\"\n",
    "except ValueError:\n",
    "    print \"value_error\"\n",
    "except AttributeError:\n",
    "    #for tchr in output_dict:\n",
    "        #for qchr in output_dict[tchr]:\n",
    "    #numb_sort = lambda k,v: [int(k), int(v)]\n",
    "    numsorted_output_dict = sorted(output_dict.items(), key=lambda t: int(t[0])) #t: numb_sort(, t[0].groups())))            \n",
    "    #numsorted_output_dict = sorted(numsorted_output_dict.keys(), key=lambda k: numsorted_output_dict[k])\n",
    "    output_dict = numsorted_output_dict\n",
    "    print \"numsorted\"\n",
    "\n",
    "#print output_dict'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Output processed data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Statistics Output NEEDS FIXING\n",
    "\n",
    "#for tchr in output_dict:\n",
    "    #for qchr in output_dict[tchr]:\n",
    "        #print np.mean(output_dict[tchr][qchr])\n",
    "        #print np.median_grouped(output_dict[tchr][qchr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Check data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check size of SynMap nested dictionary d data structure\n",
    "#for tchr in d:\n",
    "#    print \"Target Chromosome\"\n",
    "#    print tchr\n",
    "#    print len(d[tchr])\n",
    "#    for tgene in d[tchr]:\n",
    "#        print len(d[tchr][tgene])\n",
    "#print d\n",
    "\n",
    "#Check size of sorted GFF data structure \n",
    "#print gff_genes_target\n",
    "#print len(gff_genes_target)\n",
    "#print windanalysis_input_dict\n",
    "#print output_dict\n",
    "\n",
    "#print (max(output_dict.itervalues()))\n",
    "countofchrgraph = 0\n",
    "listofchrgraph = []\n",
    "\n",
    "for tchr in output_dict:\n",
    "    sumofchr = 0\n",
    "    for qchr in output_dict[tchr]:\n",
    "        try:\n",
    "            (max(output_dict[tchr][qchr].itervalues()))\n",
    "            sumofchr = sumofchr + (max(output_dict[tchr][qchr].itervalues()))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    if sumofchr > 5:\n",
    "        countofchrgraph += 1\n",
    "        listofchrgraph.append(str(tchr))\n",
    "\n",
    "listofchrgraph = natsorted(listofchrgraph)\n",
    "\n",
    "print listofchrgraph\n",
    "print countofchrgraph\n",
    "type(countofchrgraph)\n",
    "\n",
    "print len(target_lst)\n",
    "print len(output_dict)\n",
    "print len(query_api_chrs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#define figure size, column layout, grid layout\n",
    "figsize = (15, (len(query_api_chrs_final))+30)\n",
    "cols = 2\n",
    "gs = gridspec.GridSpec(len(output_dict) // cols + 1, cols)\n",
    "\n",
    "\n",
    "# These are the \"Tableau 20\" colors as RGB  \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)] \n",
    "\n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts  \n",
    "for i in range(len(tableau20)):  \n",
    "    r, g, b = tableau20[i]  \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "\n",
    "#Alternate color palettes Seaborn/Brewer\n",
    "\n",
    "current_palette = sns.color_palette(\"husl\", 40) #(\"Set2\", 30)\n",
    "#tableau20   \n",
    "\n",
    "fig = plt.figure(figsize=figsize, frameon=False)\n",
    "subplt_count = -1\n",
    "ax = []\n",
    "for tchr in listofchrgraph:\n",
    "    subplt_count += 1\n",
    "    print \"Plotting subplot: \"+str(subplt_count)\n",
    "    count = 0 \n",
    "    row = (subplt_count // cols)\n",
    "    col = subplt_count % cols\n",
    "    ax.append(fig.add_subplot(gs[row, col]))   \n",
    "    for qchr in output_dict[tchr]:\n",
    "        count += 1\n",
    "        try:\n",
    "            if (max(output_dict[tchr][qchr].itervalues()))>5:\n",
    "                x = output_dict[tchr][qchr].keys()\n",
    "                y = output_dict[tchr][qchr].values()\n",
    "                #Sets up plotting conditions\n",
    "                ax[-1].spines[\"top\"].set_visible(False)\n",
    "                ax[-1].spines[\"right\"].set_visible(False)\n",
    "                ax[-1].spines[\"left\"].set_visible(True)\n",
    "                ax[-1].spines[\"bottom\"].set_visible(True)\n",
    "                ax[-1].patch.set_visible(False)\n",
    "                ax[-1].get_xaxis().tick_bottom()\n",
    "                ax[-1].get_yaxis().tick_left()\n",
    "                ax[-1].plot(x, y, color=current_palette[count], lw=2, label=str(qchr))\n",
    "                ax[-1].set_title(label='Target Chromosome: '+species_name_filter+\" \"+ tchr, fontweight='bold', fontsize=14, y=1.1, loc='left')\n",
    "                ax[-1].set_xlabel('Window Iteration\\n(Gene number)', fontsize=12, fontweight='bold')\n",
    "                ax[-1].set_ylabel('% Retention\\n(#Syntenic genes/window size)', fontsize=12, fontweight='bold')\n",
    "                ax[-1].legend(bbox_to_anchor=(1.25, 1.13), loc=1, frameon=False, title=\"       Query\\nChromosome\", fontsize=10)\n",
    "            else:\n",
    "                continue    \n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "#fig.tight_layout(pad=2, w_pad = 6)\n",
    "fig.subplots_adjust(wspace=0.45, hspace=0.6)\n",
    "plt.savefig(\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/fractbias_figure\"+str(species_name_filter)+\".png\", transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Export Processed Fractional Bias Data to JSON File\\nimport json\\nimport csv\\n\\nwith open(\"myFile.json\", \"w\") as f:\\n    json.dump(output_dict,f)\\n    \\nx = json.loads(output_dict)\\n\\n\\n\\n\\nf = csv.writer(open(\"test.csv\", \"wb+\"))\\n\\n# Write CSV Header, If you dont need that, remove this line\\n#f.writerow([\"pk\", \"model\", \"codename\", \"name\", \"content_type\"])\\n\\nfor x in x:\\n    f.writerow([x[\"tchr\"], \\n                x[\"tchr\"][\"qchr\"]])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Export Processed Fractional Bias Data to JSON File\n",
    "import json\n",
    "import csv\n",
    "\n",
    "with open(\"myFile.json\", \"w\") as f:\n",
    "    json.dump(output_dict,f)\n",
    "    \n",
    "x = json.loads(output_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = csv.writer(open(\"test.csv\", \"wb+\"))\n",
    "\n",
    "# Write CSV Header, If you dont need that, remove this line\n",
    "#f.writerow([\"pk\", \"model\", \"codename\", \"name\", \"content_type\"])\n",
    "\n",
    "for x in x:\n",
    "    f.writerow([x[\"tchr\"], \n",
    "                x[\"tchr\"][\"qchr\"]])\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

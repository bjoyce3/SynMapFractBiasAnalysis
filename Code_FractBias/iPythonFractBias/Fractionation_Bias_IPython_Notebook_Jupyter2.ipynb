{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For importing data and parsing data\n",
    "from operator import itemgetter\n",
    "import pprint\n",
    "\n",
    "\n",
    "#Converting parsed data into raw parsed data output to csv\n",
    "import csv\n",
    "from itertools import islice, izip\n",
    "\n",
    "\n",
    "#For analyzing raw parsed data\n",
    "import collections, re\n",
    "from collections import OrderedDict\n",
    "\n",
    "    #had to uninstall python-dateutil and use old version dateutil 2.2 to avoid error\n",
    "    #sudo pip uninstall python-dateutil\n",
    "    #sudo pip install python-dateutil==2.2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "#had to install this using pip on local computer\n",
    "from natsort import natsorted, natsort_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For importing data and parsing\n",
    "synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/SorghumMaize_gcoords_merge60_syntenicdepth40.txt'\n",
    "gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/Sorghum_bicolor_6807_prodrun.gff'\n",
    "d = {}  # initialize dictionary to contain the array of syntenic genome1_chrs, genome1_genes, genome2_chrs, and genome2_genes\n",
    "genus_species = ''\n",
    "with open(gff_import_file) as gff_file:\n",
    "    for line in gff_file:\n",
    "        if line[0:15] == '##Organism name':\n",
    "            genus_species = line[17:-1]\n",
    "            species_name = genus_species.replace(' ','_')\n",
    "            species_name_filter = species_name.translate(None, '(){}[]')\n",
    "\n",
    "\n",
    "            \n",
    "#Parsed data and raw output to csv\n",
    "gff_sort_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Pina-Rice/ALL_GFF_sorted_\"+str(species_name_filter)+ \".txt\")\n",
    "synmap_dictionary_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Pina-Rice/ALL_dictionary_syntenic genes_\" +str(species_name_filter)+ \".txt\")\n",
    "gff_genes = {}  # initializes dictionary for organization of genes on chromosomes within genome1 according to start bp\n",
    "fract_bias_raw_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Pina-Rice/ALL_fractbias_\" +str(species_name_filter)+ \"output.csv\")\n",
    "\n",
    "#Analysis of parsed data\n",
    "retention_calc_output_file = (\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataOutput/Pina-Rice/Window_output_\"+str(species_name_filter+\".csv\"))\n",
    "target_lst = []\n",
    "query_lst = []\n",
    "\n",
    "def chr_id(input_dict):\n",
    "    for item in input_dict:\n",
    "        if not item in target_lst:\n",
    "            target_lst.append(item)\n",
    "        for gene in input_dict[item]:\n",
    "            for chr in input_dict[item][gene]:\n",
    "                if not chr in query_lst:\n",
    "                    query_lst.append(chr)\n",
    "\n",
    "#http://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator-in-python\n",
    "def window(seq, n):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pina & Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Pina-Rice/pina_gcoords_overlap40.txt'\n",
    "#gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Pina-Rice/Ananas_comosus_pineapple_v6.gff'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorghum & Maize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/SorghumMaize_gcoords_merge60_syntenicdepth40.txt'\n",
    "#gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Sorghum-Maize/Sorghum_bicolor_6807_prodrun.gff'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brassicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synmap_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/brassica_gcoords_merge60_syndepth1-3_overlap40.txt'\n",
    "#gff_import_file = '/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/DataInput/Brassicas/Arabidopsis_thaliana_Col-0_thale_cress_annos1-cds0-id_typename-nu1-upa1-add_chr0.gid19867.gff'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#User Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set target genome and query genome\n",
    "\n",
    "args_target = '6807' #sorghum \n",
    "#\"19867\" #arabidopsis\n",
    "#'6807' #sorghum \n",
    "#'25734'  #pina\n",
    "\n",
    "#Set whether to use all genes or \n",
    "args_all_genes = False  #True == use all genes in target genome; False == use only genes with at least one syntenic pair\n",
    "\n",
    "window_size = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and Making Data Structures\n",
    "\n",
    "Reads SynMap and GFF files and parse data into data arrays. \n",
    "\n",
    "SynMap data is put into nested dictionary called 'd':\n",
    "d{target_chr\n",
    "    {target_gene\n",
    "        {query_chr\n",
    "            {query gene}\n",
    "  }}}\n",
    "\n",
    "GFF data is put into a nested dictionary call 'gff_genes':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for tchr in d:\\n    print len(d[tchr])\\n    for qchr in d[tchr]:\\n        print len(d[tchr][qchr])'"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reads SynMap and GFF files and parse data into columns in array\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(synmap_import_file, 'r') as f:  # open SynMap file containing syntenic genes\n",
    "    synmap_rowcount = 0\n",
    "    cols = []  # list for parsing columns from SynMap data\n",
    "    for line in f:  # for loop to parse columns\n",
    "        new_line = line.replace('||', '\\t')  #converts || into tabs for universal delimination\n",
    "        if line[0] != '#' and line[0] != '\\n':  #sorts out columns containing syntenic block information/headings\n",
    "            cols = new_line.split('\\t', )  #splits all syntenic gene pair lines into parsed columns in a list\n",
    "            synmap_rowcount += 1\n",
    "            global target_chr\n",
    "            global target_gene\n",
    "            global query_chr\n",
    "            global query_gene\n",
    "            if synmap_rowcount == 1:            \n",
    "                #clean ID subgenome A from the column on left of data\n",
    "                ida = cols[0]\n",
    "                ida = ida[1:cols[0].index('_')]\n",
    "            if args_target == ida:\n",
    "                if 'scaffold' not in cols[1] and 'Scaffold' not in cols[1]:\n",
    "                    target_chr = cols[1]\n",
    "                    target_gene = str(cols[4]).rstrip(\".\")  #puts all genome1_genes with synteny into a list\n",
    "                    decimal_strip_check_target_gene = target_gene.find('.')\n",
    "                    if not decimal_strip_check_target_gene == (-1):\n",
    "                        target_gene = target_gene[:(decimal_strip_check_target_gene)]\n",
    "                if 'scaffold' not in cols[13] and 'Scaffold' not in cols[13]:\n",
    "                    query_chr = str(cols[13])  #puts all genome2_chrs with synteny to genes in genome1 into a list\n",
    "                    query_gene = str(cols[16]).rstrip(\".\")  #puts all genome2_genes with synteny to genes in a genome1 into a list\n",
    "            else:\n",
    "                if 'scaffold' not in cols[13] and 'Scaffold' not in cols[13]:\n",
    "                    target_chr = cols[13]\n",
    "                    target_gene = str(cols[16])\n",
    "                    decimal_strip_check_target_gene = target_gene.find('.')\n",
    "                    if not decimal_strip_check_target_gene == (-1):\n",
    "                        target_gene = target_gene[:(decimal_strip_check_target_gene)]\n",
    "                    #puts all genome1_genes with synteny into a list\n",
    "                if 'scaffold' not in cols[1] and 'Scaffold' not in cols[1]:\n",
    "                    query_chr = str(cols[1])  #puts all genome2_chrs with synteny to genes in genome1 into a list\n",
    "                    query_gene = cols[4].rstrip(\".1\")  #puts all genome2_genes with synteny to genes in a genome1 into a list\n",
    "                    \n",
    "            if not target_chr in d:\n",
    "                d[target_chr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "            if not target_gene in d[target_chr]:\n",
    "                d[target_chr][target_gene] = {}  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "            if not query_chr in d[target_chr][target_gene]:\n",
    "                d[target_chr][target_gene][query_chr] = query_gene  #initializes nested dictionary-third level at genome2_chr\n",
    "\n",
    "\n",
    "\n",
    "#check lengths of synmap data structure\n",
    "\"\"\"for tchr in d:\n",
    "    print len(d[tchr])\n",
    "    for qchr in d[tchr]:\n",
    "        print len(d[tchr][qchr])\"\"\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sm = 0\\nfor tchr in gff_genes:\\n    print len(gff_genes[tchr])\\n    sm = sm + len(gff_genes[tchr])\\nprint sm'"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Reads GFF from target genome and puts into data strcuture gff_genes'''\n",
    "with open(gff_import_file, 'r') as g:  # opens gff file\n",
    "    gffcols = []  #list of parsed gff columns\n",
    "    chr = []  #initialize list of chromosomes present in genome1 gff file\n",
    "    for line in g:\n",
    "        new_line = line.replace(';', '\\t')  #makes subdelims universal in gff file from CoGe\n",
    "        new_line = new_line.replace('Name=', '')  #strips Name= off gene_name in gff file from CoGe\n",
    "\n",
    "        if new_line[0] != '#' and new_line[0] != '\\n':  #selects only lines with CDS information\n",
    "            gffcols = new_line.split('\\t', )  #parses all columns\n",
    "            if gffcols[2] == 'gene' and 'scaffold' not in gffcols[0]:  #selects only 'mRNA' lines for consideration\n",
    "                chr = gffcols[0]  #adds genome1_chrs to list\n",
    "                gene_name = str(gffcols[8]).rstrip(\".\")\n",
    "                gene_name1 = gene_name[3:] #adds targetgenome_genes to list\n",
    "                start = int(gffcols[3])  #adds targetgenome_gene start bp to list for ordering as integer\n",
    "                stop = int(gffcols[4])  #adds targetgenome_gene stop bp to list ?for ordering? as integer\n",
    "                if not chr in gff_genes:\n",
    "                    gff_genes[chr] = []  #initializes chr list in dictionary if chr does not exist yet\n",
    "                gff_genes[chr].append(dict(gene_name=gene_name1, start=start, stop=stop))\n",
    "\n",
    "\n",
    "\"\"\"sm = 0\n",
    "for tchr in gff_genes:\n",
    "    print len(gff_genes[tchr])\n",
    "    sm = sm + len(gff_genes[tchr])\n",
    "print sm\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Sorts GFF genes within target chromosomes by start position'''\n",
    "gff_sort_all = {}\n",
    "gff_sort_all = natsorted(gff_genes)\n",
    "\n",
    "for chr in gff_genes:\n",
    "    gff_genes_sorted = sorted(gff_genes[chr], key=itemgetter('start'))  #Creates dictionary for searching genes against::CONSIDER sorting on midpoint of genes rather than\n",
    "    gff_genes[chr] = gff_genes_sorted    \n",
    "    \n",
    "#CONSIDER WRITING A CHECK PROGRAM TO RETURN TRUE IF ALL VALUES ARE SORTED OR FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Writes out SynMap dictionary and sorted GFF gene list to document for parsed output'''\n",
    "\n",
    "with open(str(gff_sort_output_file), 'w') as h:\n",
    "\th.write(str(gff_genes))\n",
    "with open(synmap_dictionary_output_file, 'w+') as i:\n",
    "    i.write(str(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Determine Gene Sorting Preference: all genes or at least one syntenic gene\n",
    "If args_all_genes == True\n",
    "If args_all_genes == False: SynMap data is filtered to remove any target genome genes that do not match to any genes present on the query genome chromosomes. Specifically: any {target_chr: target_gene:} that is 'False' for all query chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        print tchr\\n        print syngene_sum\\n        synsm = synsm + syngene_sum\\n        syngene_sum = 0\\n        print col2\\n        colsm = colsm + col2\\n                #if args_all_genes == False:                    \\nprint synsm\\nprint colsm'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Determine syntenic gene pairs present and output Raw Data CSV file from parsed data'''\n",
    "\n",
    "chr_id(d)\n",
    "target_lst = natsorted(target_lst)\n",
    "query_lst = natsorted(query_lst)\n",
    "windanalysis_input_dict = {}\n",
    "\"\"\"synsm = 0 #for checking data structures\n",
    "colsm = 0  #for checking data structures\"\"\"\n",
    "\n",
    "with open(str(fract_bias_raw_output_file), 'w') as csvfile:\n",
    "    headers = ['Target Chromosome', 'Target Gene Name', 'Gene Order on Target Chromosome']\n",
    "    headers.extend(query_lst)\n",
    "    headers.extend(query_lst)\n",
    "    writer = csv.writer(csvfile, dialect='excel', delimiter=',', lineterminator='\\n')\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    if args_all_genes == True:\n",
    "        for tchr in gff_genes:\n",
    "            col0 = chr #writes Pineapple chr number\n",
    "            count = 0\n",
    "            for diction in gff_genes[tchr]:\n",
    "                gene = diction['gene_name']\n",
    "                col1 = gene #writes pineapple gene name\n",
    "                count += 1\n",
    "                col2 = count #writes pineapple gene number on pineapple chr\n",
    "                #Find the query chr genes and output to columns: first gff info (col0-3), query chr (col 4-n), query chr-gene (col n+1-m)\n",
    "                syntenic_query_gene_presence_data = []\n",
    "                syntenic_query_gene_name = []\n",
    "                for qchr in query_lst:\n",
    "                    if not tchr in windanalysis_input_dict:\n",
    "                        windanalysis_input_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "                    if not qchr in windanalysis_input_dict[tchr]:\n",
    "                        windanalysis_input_dict[tchr][qchr] = []  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "                    try:\n",
    "                        syn_gene = d[tchr][gene][qchr]\n",
    "                        syntenic_query_gene_presence_data.append(True)\n",
    "                        syntenic_query_gene_name.append(syn_gene)\n",
    "                        windanalysis_input_dict[tchr][qchr].append(True)\n",
    "                    except KeyError:\n",
    "                        syntenic_query_gene_presence_data.append(False)\n",
    "                        syntenic_query_gene_name.append(\"\")\n",
    "                        windanalysis_input_dict[tchr][qchr].append(False)\n",
    "                rows = [tchr, col1, col2]\n",
    "                rows.extend(syntenic_query_gene_presence_data)\n",
    "                rows.extend(syntenic_query_gene_name)\n",
    "                writer.writerow(rows)                                           \n",
    "                    \n",
    "    elif args_all_genes == False:\n",
    "        for tchr in gff_genes:\n",
    "            col0 = chr #writes Pineapple chr number\n",
    "            count = 0\n",
    "            for diction in gff_genes[tchr]:\n",
    "                gene = diction['gene_name']\n",
    "                col1 = gene #writes pineapple gene name\n",
    "                count += 1\n",
    "                col2 = count #writes pineapple gene number on pineapple chr\n",
    "                #Find the query chr genes and output to columns: first gff info (col0-3), query chr (col 4-n), query chr-gene (col n+1-m)\n",
    "                syntenic_query_gene_presence_data = []\n",
    "                syntenic_query_gene_name = []\n",
    "                for qchr in query_lst:\n",
    "                    if not tchr in windanalysis_input_dict:\n",
    "                        windanalysis_input_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "                    if not qchr in windanalysis_input_dict[tchr]:\n",
    "                        windanalysis_input_dict[tchr][qchr] = []  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "                    try:\n",
    "                        syn_gene = d[tchr][gene][qchr]\n",
    "                        syntenic_query_gene_presence_data.append(True)\n",
    "                    except KeyError:\n",
    "                        syntenic_query_gene_presence_data.append(False)\n",
    "\n",
    "                if sum(syntenic_query_gene_presence_data) >= 1:\n",
    "                    for qchr in query_lst:\n",
    "                        try:\n",
    "                            syn_gene = d[tchr][gene][qchr]\n",
    "                            syntenic_query_gene_name.append(syn_gene)\n",
    "                            windanalysis_input_dict[tchr][qchr].append(True)\n",
    "                        except KeyError:\n",
    "                            syntenic_query_gene_name.append(\"\")\n",
    "                            windanalysis_input_dict[tchr][qchr].append(False)                    \n",
    "                    rows = [tchr, col1, col2]\n",
    "                    rows.extend(syntenic_query_gene_presence_data)\n",
    "                    rows.extend(syntenic_query_gene_name)\n",
    "                    writer.writerow(rows) \n",
    "\n",
    "                elif sum(syntenic_query_gene_presence_data) < 1:               \n",
    "                    continue\n",
    "                else:\n",
    "                    print 'Target gene not classified'\n",
    "                    continue\n",
    "\n",
    "    else:\n",
    "        print \"Genes to be used (all genes or at least one syntenic gene) are not defined\"\n",
    "\n",
    "        \n",
    "\"\"\"print len(windanalysis_input_dict)        \n",
    "for tchr in windanalysis_input_dict:\n",
    "    print tchr\n",
    "    print len(windanalysis_input_dict[tchr])\n",
    "    for qchr in windanalysis_input_dict[tchr]:\n",
    "        print qchr\n",
    "        print len(windanalysis_input_dict[tchr][qchr])\"\"\"\n",
    "\n",
    "        \n",
    "\"\"\"        print tchr\n",
    "        print syngene_sum\n",
    "        synsm = synsm + syngene_sum\n",
    "        syngene_sum = 0\n",
    "        print col2\n",
    "        colsm = colsm + col2\n",
    "                #if args_all_genes == False:                    \n",
    "print synsm\n",
    "print colsm\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Data Structures\n",
    "\n",
    "Looks through each chromosome in target genome (tchr), and goes through each gene gene on that target chromosome (determined by the GFF uploaded above according to bp position on that target chromosome) to compare to the query genome (query chromsomes). If a target gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-494-248da3791fbc>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-494-248da3791fbc>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    numsorted_output_dict = sorted(output_dict.items(), key=lambda t: int(t{0})) #t: numb_sort(, t[0].groups())))\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# '''Analysis: for each chromosome in genome1 read the genes on a chromosome and compare to subgenome array of syntenic genes'''\n",
    "\n",
    "data_output0 = []\n",
    "data_output1 = []\n",
    "data_output2 = []\n",
    "data_output3 = []\n",
    "output_dict = {}\n",
    "alphanum_output_dict = {}\n",
    "numsorted_output_dict = {}\n",
    "\n",
    "#Process windows 100genes/sliding window and \n",
    "#output to nested dictionary data structure output_dict{target chr:}{query chr}{window count:retention%}\n",
    "for tchr in windanalysis_input_dict:\n",
    "    tchr_counter = tchr\n",
    "    for qchr in windanalysis_input_dict[tchr]:\n",
    "        counter = 0\n",
    "        qchr_counter = qchr\n",
    "        if not tchr in output_dict:\n",
    "            output_dict[tchr] = {}  #initializes the nested dictionary-primary level at genome1_chromosome\n",
    "        if not qchr in output_dict[tchr]:\n",
    "            output_dict[tchr][qchr] = {}  #initializes first nesting in dictionary-second level at genome1_genes\n",
    "        try:\n",
    "            if (int(len(windanalysis_input_dict[tchr][qchr]))) >= window_size:\n",
    "                for each in window(windanalysis_input_dict[tchr][qchr], window_size):\n",
    "                    counter += 1\n",
    "                    data_output2 = float(sum(each)) / float(window_size)\n",
    "                    output_dict[tchr][qchr][counter] = round(data_output2*100.) \n",
    "                    \n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "#Sort output_dict for tchr alphanumberic at top level\n",
    "#if tchr are only integers (not alpha&numeric) the except statement will sort just integers\n",
    "try:\n",
    "    alphanumbsort = lambda k,v: [k, int(v)]\n",
    "    output_dict = collections.OrderedDict(sorted(output_dict.items(), key=lambda t: alphanumbsort(*re.match(r'([a-zA-Z]+)(\\d+)',t[0]).groups())))\n",
    "    print \"alphanum\"\n",
    "except AttributeError:\n",
    "    #for tchr in output_dict:\n",
    "        #for qchr in output_dict[tchr]:\n",
    "    #numb_sort = lambda k,v: [int(k), int(v)]\n",
    "    numsorted_output_dict = sorted(output_dict.items(), key=lambda t: int(t[0])) #t: numb_sort(, t[0].groups())))            \n",
    "    #numsorted_output_dict = sorted(numsorted_output_dict.keys(), key=lambda k: numsorted_output_dict[k])\n",
    "    output_dict = numsorted_output_dict\n",
    "    print \"numsorted\" \n",
    "    print output_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Output processed data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(retention_calc_output_file, 'wb') as csvf:\n",
    "    headers = ['Target Chromosome', 'Query Chromosome' 'Window Iteration (x-axis)']\n",
    "    headers.extend(query_lst)\n",
    "    writer = csv.writer(csvf, dialect='excel', delimiter=',', lineterminator='\\n')\n",
    "    writer.writerow(headers)\n",
    "    for tchr in windanalysis_input_dict:\n",
    "        for qchr in windanalysis_input_dict[tchr]:            \n",
    "            #Prints into two columns\n",
    "            writer.writerows(izip( output_dict[tchr][qchr]))\n",
    "\n",
    "##Statistics Output NEEDS FIXING\n",
    "\n",
    "#for tchr in output_dict:\n",
    "    #for qchr in output_dict[tchr]:\n",
    "        #print np.mean(output_dict[tchr][qchr])\n",
    "        #print np.median_grouped(output_dict[tchr][qchr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#define figure size, column layout, grid layout\n",
    "figsize = (15, (len(target_lst)*2.4))\n",
    "cols = 2\n",
    "gs = gridspec.GridSpec(len(output_dict) // cols + 1, cols)\n",
    "\n",
    "\n",
    "\n",
    "# These are the \"Tableau 20\" colors as RGB  \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)] \n",
    "\n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts  \n",
    "for i in range(len(tableau20)):  \n",
    "    r, g, b = tableau20[i]  \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "\n",
    "#Alternate color palettes Seaborn/Brewer\n",
    "\n",
    "current_palette = sns.color_palette(\"Set2\", 40)\n",
    "#tableau20   \n",
    "\n",
    "fig = plt.figure(figsize=figsize, frameon=False)\n",
    "subplt_count = -1\n",
    "ax = []\n",
    "for tchr in output_dict:\n",
    "    subplt_count += 1\n",
    "    print \"Plotting subplot: \"+str(subplt_count)\n",
    "    count = 0 \n",
    "    row = (subplt_count // cols)\n",
    "    col = subplt_count % cols\n",
    "    ax.append(fig.add_subplot(gs[row, col]))   \n",
    "    for qchr in output_dict[tchr]:\n",
    "        count += 1\n",
    "        if (max(output_dict[tchr][qchr].itervalues()))>0:\n",
    "            x = output_dict[tchr][qchr].keys()\n",
    "            y = output_dict[tchr][qchr].values()\n",
    "            #Sets up plotting conditions\n",
    "            ax[-1].spines[\"top\"].set_visible(False)\n",
    "            ax[-1].spines[\"right\"].set_visible(False)\n",
    "            ax[-1].spines[\"left\"].set_visible(True)\n",
    "            ax[-1].spines[\"bottom\"].set_visible(True)\n",
    "            ax[-1].patch.set_visible(False)\n",
    "            ax[-1].get_xaxis().tick_bottom()\n",
    "            ax[-1].get_yaxis().tick_left()\n",
    "            ax[-1].plot(x, y, color=current_palette[count], lw=2, label=str(qchr))\n",
    "            ax[-1].set_title(label='Target Chromosome: '+species_name_filter+\" \"+ tchr, fontweight='bold', fontsize=14, y=1.1, loc='left')\n",
    "            ax[-1].set_xlabel('Window Iteration\\n(Gene number)', fontsize=12, fontweight='bold')\n",
    "            ax[-1].set_ylabel('% Retention\\n(#Syntenic genes/window size)', fontsize=12, fontweight='bold')\n",
    "            ax[-1].legend(bbox_to_anchor=(1.25, 1.1), loc=1, frameon=False, title=\"       Query\\nChromosome\", fontsize=10)\n",
    "            \n",
    "        else:\n",
    "            continue        \n",
    "\n",
    "fig.subplots_adjust(wspace=0.45, hspace=0.6)\n",
    "plt.savefig(\"/Users/bjoyce3/Desktop/SynMapFractBiasAnalysis/fractbias_figure\"+str(species_name_filter)+\".png\", transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Export Processed Fractional Bias Data to JSON File\n",
    "import json\n",
    "import csv\n",
    "\n",
    "with open(\"myFile.json\", \"w\") as f:\n",
    "    json.dump(output_dict,f)\n",
    "    \n",
    "x = json.loads(output_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = csv.writer(open(\"test.csv\", \"wb+\"))\n",
    "\n",
    "# Write CSV Header, If you dont need that, remove this line\n",
    "#f.writerow([\"pk\", \"model\", \"codename\", \"name\", \"content_type\"])\n",
    "\n",
    "for x in x:\n",
    "    f.writerow([x[\"tchr\"], \n",
    "                x[\"tchr\"][\"qchr\"]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''import os\n",
    "from lightning import Lightning\n",
    "\n",
    "from numpy import random, asarray, arange\n",
    "from sklearn import datasets\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from seaborn import color_palette\n",
    "\n",
    "\n",
    "# replace with your own host and credentials, e.g. http://localhost:3000 or http://my-lightning-server.herokuapp.com\n",
    "host = 'http://lightning-docs.herokuapp.com'\n",
    "auth = (os.getenv('LIGHTNING_USERNAME'), os.getenv('LIGHTNING_PASSWORD'))\n",
    "\n",
    "lgn = Lightning(ipython=True, host=host, auth=auth)\n",
    "lgn.create_session('fractbias');'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
